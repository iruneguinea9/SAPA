{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Concatenate\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que queremos predecir dos objetivos diferentes (por ejemplo, precio y categoría) a partir de dos conjuntos de características diferentes (por ejemplo, características visuales y características de texto de un producto).\n",
    "\n",
    "* Características visuales: un conjunto de 128 características numéricas, que podrían representar, por ejemplo, valores de píxeles o características extraídas de imágenes.\n",
    "* Características de texto: un conjunto de 256 características numéricas, representando posiblemente la codificación de texto o características lingüísticas.\n",
    "* Precio (Salida 1): un valor numérico que representa el precio de un producto.\n",
    "* Categoría (Salida 2): una etiqueta de categoría, que asumiremos que puede tomar 10 valores diferentes (por ejemplo, 10 categorías diferentes de productos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a generar datos aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de datos ficticios\n",
    "num_muestras = 1000  # Número de muestras en el conjunto de datos\n",
    "\n",
    "# Características visuales: 128 características numéricas\n",
    "caracteristicas_visuales = np.random.rand(num_muestras, 128)\n",
    "\n",
    "# Características de texto: 256 características numéricas\n",
    "caracteristicas_texto = np.random.rand(num_muestras, 256)\n",
    "\n",
    "# Precio (Salida 1): Valor numérico (por ejemplo, precio de un producto)\n",
    "precio = np.random.rand(num_muestras, 1)\n",
    "\n",
    "# Categoría (Salida 2): 10 categorías posibles (codificadas en one-hot)\n",
    "categorias = np.random.randint(0, 10, size=(num_muestras, 1))\n",
    "categorias_one_hot = tf.keras.utils.to_categorical(categorias, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide los datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vis_train, x_vis_test, x_text_train, x_text_test, y_precio_train, y_precio_test, y_cat_train, y_cat_test = train_test_split(\n",
    "    caracteristicas_visuales,\n",
    "    caracteristicas_texto,\n",
    "    precio,\n",
    "    categorias_one_hot,\n",
    "    test_size=0.2,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye el modelo:\n",
    "* Crea dos ramas de entrada, una para cada tipo de características.\n",
    "* Las ramas se fusionarán para predecir el precio.\n",
    "* Una de las ramas se utilizará también para predecir la categoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El esquema es el siguiente:\n",
    "\n",
    "<img src=\"Datos/esquema_modelo_funcional.png\" alt=\"esquema modelo funcional\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\irune\\OneDrive\\Desktop\\IABD\\SAPA\\SAPA\\SAPA\\.conda\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Texto         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ oculta_texto_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ Input_Texto[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Input_Visual        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ oculta_texto_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ oculta_texto_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ oculta_visual       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ Input_Visual[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ features            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ oculta_visual[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ oculta_texto_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ salida_categoria    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ oculta_texto_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ salida_precio       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Texto         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ oculta_texto_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ Input_Texto[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Input_Visual        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ oculta_texto_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ oculta_texto_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ oculta_visual       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ Input_Visual[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ features            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ oculta_visual[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ oculta_texto_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ salida_categoria    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │        \u001b[38;5;34m650\u001b[0m │ oculta_texto_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ salida_precio       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,187</span> (196.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,187\u001b[0m (196.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,187</span> (196.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,187\u001b[0m (196.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Limpiar sesión y establecer semilla\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(17)\n",
    "\n",
    "# Definir entradas\n",
    "input_visual = tf.keras.layers.Input(shape=(128,), name=\"Input_Visual\")\n",
    "input_texto = tf.keras.layers.Input(shape=(256,), name=\"Input_Texto\")\n",
    "\n",
    "# Rama visual\n",
    "hidden_visual = tf.keras.layers.Dense(64, activation=\"relu\", name=\"oculta_visual\")(input_visual)\n",
    "\n",
    "# Rama de texto más profunda\n",
    "hidden_texto = tf.keras.layers.Dense(128, activation=\"relu\", name=\"oculta_texto_1\")(input_texto)\n",
    "hidden_texto = tf.keras.layers.Dense(64, activation=\"relu\", name=\"oculta_texto_2\")(hidden_texto)\n",
    "\n",
    "# Concatenación de ambas ramas\n",
    "combinacion = tf.keras.layers.Concatenate(name=\"features\")([hidden_visual, hidden_texto])\n",
    "\n",
    "# Salida de categoría basada en la rama de texto\n",
    "salida_categoria = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"salida_categoria\")(hidden_texto)\n",
    "\n",
    "# Salida de precio basada en la combinación\n",
    "salida_precio = tf.keras.layers.Dense(1, name=\"salida_precio\")(combinacion)\n",
    "\n",
    "# Definir modelo\n",
    "model = tf.keras.Model(inputs=[input_visual, input_texto], outputs=[salida_categoria, salida_precio])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba creando una imagen del modelo que es igual que el que se pide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \"modelo.png\", show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo tengo todo instalado pero no me funciona, probar en el pc de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compila el modelo especificando las pérdidas y métricas para cada salida (utiliza el optimizador Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss={\n",
    "        \"salida_categoria\": \"categorical_crossentropy\", # Clasificacion\n",
    "        \"salida_precio\": \"mse\" # Regresion\n",
    "    },\n",
    "    metrics={\n",
    "        \"salida_categoria\": [\"accuracy\"], # Clasificacion\n",
    "        \"salida_precio\": [\"mae\"] # Regresion\n",
    "    }\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irune\\OneDrive\\Desktop\\IABD\\SAPA\\SAPA\\SAPA\\.conda\\Lib\\site-packages\\keras\\src\\models\\functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['Input_Visual', 'Input_Texto']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.6298 - salida_categoria_accuracy: 0.1057 - salida_categoria_loss: 2.4157 - salida_precio_loss: 0.2140 - salida_precio_mae: 0.3749 - val_loss: 2.4942 - val_salida_categoria_accuracy: 0.1063 - val_salida_categoria_loss: 2.3462 - val_salida_precio_loss: 0.1480 - val_salida_precio_mae: 0.3155\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4763 - salida_categoria_accuracy: 0.1080 - salida_categoria_loss: 2.3418 - salida_precio_loss: 0.1346 - salida_precio_mae: 0.3016 - val_loss: 2.4458 - val_salida_categoria_accuracy: 0.1312 - val_salida_categoria_loss: 2.3148 - val_salida_precio_loss: 0.1310 - val_salida_precio_mae: 0.2986\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4387 - salida_categoria_accuracy: 0.1189 - salida_categoria_loss: 2.3132 - salida_precio_loss: 0.1256 - salida_precio_mae: 0.2893 - val_loss: 2.4318 - val_salida_categoria_accuracy: 0.1312 - val_salida_categoria_loss: 2.3031 - val_salida_precio_loss: 0.1287 - val_salida_precio_mae: 0.2947\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4180 - salida_categoria_accuracy: 0.1388 - salida_categoria_loss: 2.2971 - salida_precio_loss: 0.1209 - salida_precio_mae: 0.2852 - val_loss: 2.4230 - val_salida_categoria_accuracy: 0.1125 - val_salida_categoria_loss: 2.2976 - val_salida_precio_loss: 0.1254 - val_salida_precio_mae: 0.2910\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4031 - salida_categoria_accuracy: 0.1457 - salida_categoria_loss: 2.2868 - salida_precio_loss: 0.1163 - salida_precio_mae: 0.2799 - val_loss: 2.4165 - val_salida_categoria_accuracy: 0.1125 - val_salida_categoria_loss: 2.2940 - val_salida_precio_loss: 0.1225 - val_salida_precio_mae: 0.2877\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3891 - salida_categoria_accuracy: 0.1515 - salida_categoria_loss: 2.2774 - salida_precio_loss: 0.1116 - salida_precio_mae: 0.2746 - val_loss: 2.4133 - val_salida_categoria_accuracy: 0.1125 - val_salida_categoria_loss: 2.2928 - val_salida_precio_loss: 0.1204 - val_salida_precio_mae: 0.2854\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3780 - salida_categoria_accuracy: 0.1719 - salida_categoria_loss: 2.2697 - salida_precio_loss: 0.1083 - salida_precio_mae: 0.2711 - val_loss: 2.4120 - val_salida_categoria_accuracy: 0.1125 - val_salida_categoria_loss: 2.2928 - val_salida_precio_loss: 0.1192 - val_salida_precio_mae: 0.2845\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3660 - salida_categoria_accuracy: 0.1887 - salida_categoria_loss: 2.2620 - salida_precio_loss: 0.1040 - salida_precio_mae: 0.2658 - val_loss: 2.4103 - val_salida_categoria_accuracy: 0.1063 - val_salida_categoria_loss: 2.2921 - val_salida_precio_loss: 0.1182 - val_salida_precio_mae: 0.2835\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3558 - salida_categoria_accuracy: 0.1905 - salida_categoria_loss: 2.2548 - salida_precio_loss: 0.1010 - salida_precio_mae: 0.2618 - val_loss: 2.4088 - val_salida_categoria_accuracy: 0.1125 - val_salida_categoria_loss: 2.2913 - val_salida_precio_loss: 0.1175 - val_salida_precio_mae: 0.2830\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.3463 - salida_categoria_accuracy: 0.1939 - salida_categoria_loss: 2.2481 - salida_precio_loss: 0.0982 - salida_precio_mae: 0.2583 - val_loss: 2.4078 - val_salida_categoria_accuracy: 0.1250 - val_salida_categoria_loss: 2.2909 - val_salida_precio_loss: 0.1169 - val_salida_precio_mae: 0.2821\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_vis_train, x_text_train],\n",
    "    [y_cat_train, y_precio_train],\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalúa el modelo en el conjunt de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4504 - salida_categoria_accuracy: 0.1354 - salida_categoria_loss: 2.3141 - salida_precio_loss: 0.1337 - salida_precio_mae: 0.2979  \n",
      "Loss: 2.437218427658081\n",
      "Exactitud - Categoría: 2.2997775077819824\n",
      "MAE - Precio: 0.12720727920532227\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(\n",
    "    [x_vis_test, x_text_test], \n",
    "    [y_cat_test, y_precio_test]\n",
    ")\n",
    "\n",
    "print(f\"Loss: {results[0]}\")\n",
    "print(f\"Exactitud - Categoría: { results[1]}\")\n",
    "print(f\"MAE - Precio: {results[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es entrenar un modelo en un subconjunto de clases (Modelo A) y luego usar este modelo para entrenar otro modelo en un subconjunto diferente de clases (Modelo B), primero sin y luego con el conocimiento transferido del Modelo A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga los datos de CIFAR-10, representa alguna de sus imágenes con sus etiquetas, haz una lista con las etiquetas que tiene (busca en internet) y normaliza los datos dividiendo entre 255.0.\n",
    "\n",
    "Divide los datos en conjuntos de entrenamiento, pruebas y validación para el modelo A y para el modelo B:\n",
    "* El modelo A utiliza las clases \"avión\", \"automóvil\", \"pájaro\" y \"gato\"\n",
    "* El modelo B utiliza las clases \"ciervo\", \"perro\", \"rana\" y \"caballo\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo A:\n",
      "Clases: ['avión', 'automóvil', 'pájaro', 'gato']\n",
      "Datos de entrenamiento: (20000, 32, 32, 3)\n",
      "Etiquetas de entrenamiento: (20000, 1)\n",
      "Datos de prueba: (4000, 32, 32, 3)\n",
      "\n",
      "Modelo B:\n",
      "Clases: ['ciervo', 'perro', 'rana', 'caballo']\n",
      "Datos de entrenamiento: (20000, 32, 32, 3)\n",
      "Etiquetas de entrenamiento: (20000, 1)\n",
      "Datos de prueba: (4000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Etiquetas\n",
    "labels = ['avión', 'automóvil', 'pájaro', 'gato', 'ciervo', \n",
    "          'perro', 'rana', 'caballo', 'barco', 'camión']\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalizar datos\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "def filtro_de_clases(x, y, selected_classes):\n",
    "    mask = np.isin(y.flatten(), selected_classes)\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "# Clases para Modelo A y B\n",
    "modelo_a_clases = [0, 1, 2, 3]  \n",
    "modelo_b_clases = [4, 5, 6, 7]  \n",
    "\n",
    "# Filtrar datos para Modelo A\n",
    "x_train_a, y_train_a = filtro_de_clases(x_train, y_train, modelo_a_clases)\n",
    "x_test_a, y_test_a = filtro_de_clases(x_test, y_test, modelo_a_clases)\n",
    "\n",
    "y_train_a = np.array([modelo_a_clases.index(label) for label in y_train_a.flatten()]).reshape(-1, 1)\n",
    "y_test_a = np.array([modelo_a_clases.index(label) for label in y_test_a.flatten()]).reshape(-1, 1)\n",
    "\n",
    "# Filtrar datos para Modelo B\n",
    "x_train_b, y_train_b = filtro_de_clases(x_train, y_train, modelo_b_clases)\n",
    "x_test_b, y_test_b = filtro_de_clases(x_test, y_test, modelo_b_clases)\n",
    "\n",
    "y_train_b = np.array([modelo_b_clases.index(label) for label in y_train_b.flatten()]).reshape(-1, 1)\n",
    "y_test_b = np.array([modelo_b_clases.index(label) for label in y_test_b.flatten()]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Imprimir información de los conjuntos de datos\n",
    "print(\"Modelo A:\")\n",
    "print(f\"Clases: {[labels[i] for i in modelo_a_clases]}\")\n",
    "print(f\"Datos de entrenamiento: {x_train_a.shape}\")\n",
    "print(f\"Etiquetas de entrenamiento: {y_train_a.shape}\")\n",
    "print(f\"Datos de prueba: {x_test_a.shape}\")\n",
    "\n",
    "print(\"\\nModelo B:\")\n",
    "print(f\"Clases: {[labels[i] for i in modelo_b_clases]}\")\n",
    "print(f\"Datos de entrenamiento: {x_train_b.shape}\")\n",
    "print(f\"Etiquetas de entrenamiento: {y_train_b.shape}\")\n",
    "print(f\"Datos de prueba: {x_test_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_train_a[0])\n",
    "plt.title(f'Ejemplo: {labels[modelo_a_clases[y_train_a[0][0]]]}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena el Modelo A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.4624 - loss: 1.2415 - val_accuracy: 0.6130 - val_loss: 1.0037\n",
      "Epoch 2/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.5893 - loss: 1.0120 - val_accuracy: 0.6308 - val_loss: 0.9466\n",
      "Epoch 3/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6258 - loss: 0.9426 - val_accuracy: 0.6255 - val_loss: 0.9250\n",
      "Epoch 4/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6413 - loss: 0.8973 - val_accuracy: 0.6317 - val_loss: 0.9016\n",
      "Epoch 5/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6541 - loss: 0.8653 - val_accuracy: 0.6378 - val_loss: 0.8896\n",
      "Epoch 6/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - accuracy: 0.6682 - loss: 0.8318 - val_accuracy: 0.6500 - val_loss: 0.8707\n",
      "Epoch 7/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.6893 - loss: 0.8056 - val_accuracy: 0.6572 - val_loss: 0.8545\n",
      "Epoch 8/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.6917 - loss: 0.7851 - val_accuracy: 0.6700 - val_loss: 0.8278\n",
      "Epoch 9/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7037 - loss: 0.7692 - val_accuracy: 0.6630 - val_loss: 0.8512\n",
      "Epoch 10/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7046 - loss: 0.7590 - val_accuracy: 0.6733 - val_loss: 0.8285\n",
      "Epoch 11/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.7110 - loss: 0.7446 - val_accuracy: 0.6735 - val_loss: 0.8362\n",
      "Epoch 12/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.7127 - loss: 0.7380 - val_accuracy: 0.6745 - val_loss: 0.8272\n",
      "Epoch 13/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.7198 - loss: 0.7226 - val_accuracy: 0.6708 - val_loss: 0.8371\n",
      "Epoch 14/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.7258 - loss: 0.7120 - val_accuracy: 0.6737 - val_loss: 0.8279\n",
      "Epoch 15/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7272 - loss: 0.7013 - val_accuracy: 0.6720 - val_loss: 0.8385\n",
      "Epoch 16/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.7310 - loss: 0.6924 - val_accuracy: 0.6670 - val_loss: 0.8497\n",
      "Epoch 17/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.7318 - loss: 0.6837 - val_accuracy: 0.6620 - val_loss: 0.8619\n",
      "Epoch 18/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7357 - loss: 0.6803 - val_accuracy: 0.6670 - val_loss: 0.8484\n",
      "Epoch 19/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7374 - loss: 0.6764 - val_accuracy: 0.6590 - val_loss: 0.8571\n",
      "Epoch 20/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.7374 - loss: 0.6676 - val_accuracy: 0.6702 - val_loss: 0.8545\n",
      "Epoch 21/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7436 - loss: 0.6568 - val_accuracy: 0.6758 - val_loss: 0.8353\n",
      "Epoch 22/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.7475 - loss: 0.6509 - val_accuracy: 0.6827 - val_loss: 0.8292\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6869 - loss: 0.8091\n",
      "Precisión en test: 0.6837499737739563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "os.makedirs('Checkpoints', exist_ok=True)\n",
    "os.makedirs('modelos/4_7_2', exist_ok=True)\n",
    "\n",
    "# Preparar los datos\n",
    "x_train_a = x_train_a.reshape(-1, 32, 32, 3)\n",
    "x_test_a = x_test_a.reshape(-1, 32, 32, 3)\n",
    "\n",
    "# Dividir en entrenamiento y validación\n",
    "x_train_a, x_val_a, y_train_a, y_val_a = train_test_split(\n",
    "    x_train_a, y_train_a, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Crear el modelo A\n",
    "model_A = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(32,32,3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # 4 grupos\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_A.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"Checkpoints/4_7_2.weights.h5\", \n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "# Para que el modelo pare si en 10 iteraciones no mejora\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "history_A = model_A.fit(\n",
    "    x_train_a,\n",
    "    y_train_a,\n",
    "    epochs=100,\n",
    "    validation_data=(x_val_a, y_val_a),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_accuracy = model_A.evaluate(x_test_a, y_test_a)\n",
    "print(f\"Precisión en test: {test_accuracy}\")\n",
    "\n",
    "# Guardar el modelo\n",
    "model_A.save(\"modelos/4_7_2/modelo_A.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el Modelo B desde 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.3923 - loss: 1.3214 - val_accuracy: 0.4453 - val_loss: 1.2002\n",
      "Epoch 2/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5105 - loss: 1.1167 - val_accuracy: 0.4755 - val_loss: 1.1658\n",
      "Epoch 3/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.5417 - loss: 1.0626 - val_accuracy: 0.4913 - val_loss: 1.1618\n",
      "Epoch 4/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5628 - loss: 1.0243 - val_accuracy: 0.5013 - val_loss: 1.1520\n",
      "Epoch 5/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5692 - loss: 1.0158 - val_accuracy: 0.4960 - val_loss: 1.1947\n",
      "Epoch 6/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5846 - loss: 0.9952 - val_accuracy: 0.4945 - val_loss: 1.1976\n",
      "Epoch 7/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5918 - loss: 0.9826 - val_accuracy: 0.5038 - val_loss: 1.1659\n",
      "Epoch 8/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6029 - loss: 0.9608 - val_accuracy: 0.5207 - val_loss: 1.1434\n",
      "Epoch 9/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6093 - loss: 0.9422 - val_accuracy: 0.5390 - val_loss: 1.0884\n",
      "Epoch 10/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6176 - loss: 0.9346 - val_accuracy: 0.5153 - val_loss: 1.1652\n",
      "Epoch 11/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.6198 - loss: 0.9270 - val_accuracy: 0.5472 - val_loss: 1.0746\n",
      "Epoch 12/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6240 - loss: 0.9117 - val_accuracy: 0.5365 - val_loss: 1.1072\n",
      "Epoch 13/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.6277 - loss: 0.9057 - val_accuracy: 0.5490 - val_loss: 1.0899\n",
      "Epoch 14/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6310 - loss: 0.8911 - val_accuracy: 0.5468 - val_loss: 1.1006\n",
      "Epoch 15/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.6356 - loss: 0.8843 - val_accuracy: 0.5552 - val_loss: 1.0935\n",
      "Epoch 16/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.6393 - loss: 0.8766 - val_accuracy: 0.5362 - val_loss: 1.1277\n",
      "Epoch 17/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6396 - loss: 0.8755 - val_accuracy: 0.5443 - val_loss: 1.1326\n",
      "Epoch 18/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6410 - loss: 0.8706 - val_accuracy: 0.5430 - val_loss: 1.1387\n",
      "Epoch 19/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6482 - loss: 0.8581 - val_accuracy: 0.5405 - val_loss: 1.1556\n",
      "Epoch 20/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6491 - loss: 0.8588 - val_accuracy: 0.5335 - val_loss: 1.1654\n",
      "Epoch 21/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6502 - loss: 0.8541 - val_accuracy: 0.5318 - val_loss: 1.1696\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 1.0333\n",
      "Precision in test: 0.5727499723434448\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "x_train_b = x_train_b.reshape(-1, 32, 32, 3)\n",
    "x_test_b = x_test_b.reshape(-1, 32, 32, 3)\n",
    "\n",
    "# Split into training and validation sets\n",
    "x_train_b, x_val_b, y_train_b, y_val_b = train_test_split(\n",
    "    x_train_b, y_train_b, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create Model B\n",
    "model_B = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(32,32,3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')  # 4 groups\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_B.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"Checkpoints/4_7_2_B.weights.h5\", \n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history_B = model_B.fit(\n",
    "    x_train_b,\n",
    "    y_train_b,\n",
    "    epochs=100,\n",
    "    validation_data=(x_val_b, y_val_b),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_B.evaluate(x_test_b, y_test_b)\n",
    "print(f\"Precision en test: {test_accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "model_B.save(\"modelos/4_7_2/modelo_B.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar el Modelo B utilizando las capas aprendidas del Modelo A (excepto la capa de salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3185 - loss: 1.7465 - val_accuracy: 0.4252 - val_loss: 1.2804\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4326 - loss: 1.2622 - val_accuracy: 0.4507 - val_loss: 1.2272\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4622 - loss: 1.2190 - val_accuracy: 0.4625 - val_loss: 1.2072\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4759 - loss: 1.1995 - val_accuracy: 0.4665 - val_loss: 1.1968\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4823 - loss: 1.1882 - val_accuracy: 0.4723 - val_loss: 1.1908\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4875 - loss: 1.1813 - val_accuracy: 0.4740 - val_loss: 1.1871\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4913 - loss: 1.1763 - val_accuracy: 0.4798 - val_loss: 1.1847\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4926 - loss: 1.1728 - val_accuracy: 0.4848 - val_loss: 1.1830\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4923 - loss: 1.1703 - val_accuracy: 0.4837 - val_loss: 1.1818\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4916 - loss: 1.1684 - val_accuracy: 0.4882 - val_loss: 1.1809\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4923 - loss: 1.1669 - val_accuracy: 0.4880 - val_loss: 1.1802\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4929 - loss: 1.1658 - val_accuracy: 0.4865 - val_loss: 1.1798\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4928 - loss: 1.1649 - val_accuracy: 0.4865 - val_loss: 1.1794\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4939 - loss: 1.1641 - val_accuracy: 0.4865 - val_loss: 1.1791\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4945 - loss: 1.1635 - val_accuracy: 0.4865 - val_loss: 1.1789\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4955 - loss: 1.1632 - val_accuracy: 0.4873 - val_loss: 1.1787\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4954 - loss: 1.1626 - val_accuracy: 0.4873 - val_loss: 1.1786\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4964 - loss: 1.1623 - val_accuracy: 0.4873 - val_loss: 1.1785\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4963 - loss: 1.1620 - val_accuracy: 0.4880 - val_loss: 1.1784\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4960 - loss: 1.1618 - val_accuracy: 0.4885 - val_loss: 1.1784\n",
      "Epoch 1/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4817 - loss: 1.1765 - val_accuracy: 0.5343 - val_loss: 1.0958\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5459 - loss: 1.0752 - val_accuracy: 0.5533 - val_loss: 1.0559\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5616 - loss: 1.0342 - val_accuracy: 0.5565 - val_loss: 1.0375\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5790 - loss: 1.0005 - val_accuracy: 0.5755 - val_loss: 1.0178\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5955 - loss: 0.9736 - val_accuracy: 0.5770 - val_loss: 1.0087\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6014 - loss: 0.9547 - val_accuracy: 0.5732 - val_loss: 1.0090\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6095 - loss: 0.9384 - val_accuracy: 0.5775 - val_loss: 0.9951\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6156 - loss: 0.9260 - val_accuracy: 0.5805 - val_loss: 0.9995\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6244 - loss: 0.9083 - val_accuracy: 0.5842 - val_loss: 1.0125\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6276 - loss: 0.8984 - val_accuracy: 0.5888 - val_loss: 0.9915\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6382 - loss: 0.8827 - val_accuracy: 0.5910 - val_loss: 1.0003\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6443 - loss: 0.8704 - val_accuracy: 0.5940 - val_loss: 0.9886\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.6445 - loss: 0.8577 - val_accuracy: 0.5882 - val_loss: 1.0106\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.6527 - loss: 0.8511 - val_accuracy: 0.5900 - val_loss: 0.9921\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.6577 - loss: 0.8400 - val_accuracy: 0.5990 - val_loss: 0.9917\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6610 - loss: 0.8301 - val_accuracy: 0.6003 - val_loss: 1.0008\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6642 - loss: 0.8238 - val_accuracy: 0.5990 - val_loss: 0.9991\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6689 - loss: 0.8174 - val_accuracy: 0.5965 - val_loss: 1.0061\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6674 - loss: 0.8099 - val_accuracy: 0.5987 - val_loss: 1.0070\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.6755 - loss: 0.7978 - val_accuracy: 0.6010 - val_loss: 1.0008\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6091 - loss: 0.9590\n",
      "Precision en test: 0.6184999942779541\n"
     ]
    }
   ],
   "source": [
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "\n",
    "# Modelo de B con las capas de A (menos la última)\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_frozen = model_B_on_A.fit(\n",
    "    x_train_b, \n",
    "    y_train_b, \n",
    "    epochs=20, \n",
    "    validation_data=(x_val_b, y_val_b)\n",
    ")\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_unfrozen = model_B_on_A.fit(\n",
    "    x_train_b, \n",
    "    y_train_b, \n",
    "    epochs=20, \n",
    "    validation_data=(x_val_b, y_val_b)\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model_B_on_A.evaluate(x_test_b, y_test_b)\n",
    "print(f\"Precision en test: {test_accuracy}\")\n",
    "\n",
    "model_B_on_A.save(\"modelos/4_7_2/modelo_B_transferencia.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar los dos modelos para el conjunto de datos B en el conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación de Modelo B original:\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 1.0333\n",
      "Precisión en test: 0.5727499723434448\n",
      "\n",
      "Evaluación de Modelo B basado en A:\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6091 - loss: 0.9590\n",
      "Precisión en test: 0.6184999942779541\n"
     ]
    }
   ],
   "source": [
    "# Evaluar Modelo B original\n",
    "print(\"Evaluación de Modelo B original:\")\n",
    "test_loss, test_accuracy = model_B.evaluate(x_test_b, y_test_b)\n",
    "print(f\"Precisión en test: {test_accuracy}\")\n",
    "\n",
    "# Evaluar Modelo B basado en A\n",
    "print(\"\\nEvaluación de Modelo B basado en A:\")\n",
    "test_loss, test_accuracy = model_B_on_A.evaluate(x_test_b, y_test_b)\n",
    "print(f\"Precisión en test: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿En este caso merece la pena?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sí, da mejor precisión"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
