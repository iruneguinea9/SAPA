{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier,StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has entrenado cinco modelos diferentes en el mismo conjunto de entrenamiento exacto y todos consiguen una precisión del 95%, ¿hay alguna posibilidad de que puedas combinar estos modelos para obtener mejores resultados? \n",
    "\n",
    "Si la respuesta es sí, ¿cómo? Si la respuesta es no, ¿por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si, se pueden combinar. Hay varios metodos de combinación, el de votación, el de la media, el boosting y el bagging. Habría que elegir el adecuado. Al combinar modelos, podemos mejorar la precisión al basarse en los diferentes modelos en vez de en uno. Además, si los modelos estan entrenados con diferentes datos, esa diversidad puede ser clave para mejorar la precisión, ya que tendrá más valores de los que aprender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el conjunto de datos MNIST y divídelo en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba (por ejemplo, utiliza 50.000 instancias para entrenamiento, 10.000 para validación y 10.000 para pruebas). \n",
    "\n",
    "Después, entrena varios clasificadores diferentes (uno de ellos que sea un árbol de decisión). \n",
    "\n",
    "A continuación, intenta combinarlos en un ensamble que supere en rendimiento a cada clasificador individual del conjunto de validación, utilizando hard voting. \n",
    "\n",
    "Una vez que hayas encontrado uno, pruébalo en el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame=False, parser=\"auto\")\n",
    "X_mnist = mnist.data\n",
    "y_mnist =  mnist.target\n",
    "\n",
    "# 50.000 para entrenamiento\n",
    "X_train, y_train = X_mnist[:50_000], y_mnist[:50_000]\n",
    "# Las siguientes 10.000 para validación\n",
    "X_valid, y_valid = X_mnist[50_000:60_000], y_mnist[50_000:60_000]\n",
    "\n",
    "# Y las siguientes 10.000 para pruebas\n",
    "X_test, y_test = X_mnist[60_000:], y_mnist[60_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando DecisionTreeClassifier\n",
      "Entrenando RandomForestClassifier\n",
      "Entrenando SVC\n",
      "Entrenando KNeighborsClassifier\n",
      "Precisión del conjunto de validación: 0.9788\n",
      "Precisión del conjunto de prueba: 0.974\n"
     ]
    }
   ],
   "source": [
    "# usar los clasifiers\n",
    "arbol_decision = DecisionTreeClassifier(random_state=42)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "svm = SVC(random_state=42)\n",
    "kvecinos = KNeighborsClassifier()\n",
    "\n",
    "# Agrupar todos los estimadores en una lista para facilitar el procesamiento\n",
    "estimadores = [arbol_decision, random_forest, svm, kvecinos]\n",
    "\n",
    "# Entrenar cada estimador individualmente\n",
    "for estimator in estimadores:\n",
    "    print(\"Entrenando\", estimator.__class__.__name__)\n",
    "    estimator.fit(X_train, y_train)  # Entrenar el modelo con los datos de entrenamiento\n",
    "\n",
    "# Obtener las puntuaciones de validación para cada estimador\n",
    "# Calcula y almacena la precisión de cada modelo en los datos de validación\n",
    "scores = [estimator.score(X_valid, y_valid) for estimator in estimadores]\n",
    "\n",
    "# Asignar nombres a los estimadores para usarlos en el VotingClassifier\n",
    "named_estimators = [\n",
    "    (\"Árbol de decisión\", arbol_decision),\n",
    "    (\"Random Forest\", random_forest),\n",
    "    (\"SVM\", svm),\n",
    "    (\"KVecinos\", kvecinos)\n",
    "]\n",
    "\n",
    "# Crear un clasificador de votación que combina las predicciones de múltiples modelos\n",
    "voting_clf = VotingClassifier(estimators=named_estimators)\n",
    "\n",
    "# Entrenar el VotingClassifier con los datos de entrenamiento\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el VotingClassifier en los datos de validación\n",
    "error_val = voting_clf.score(X_valid, y_valid)\n",
    "print(\"Precisión del conjunto de validación:\", error_val)\n",
    "\n",
    "# Evaluar el VotingClassifier en los datos de prueba\n",
    "error_test = voting_clf.score(X_test, y_test)\n",
    "print(\"Precisión del conjunto de prueba:\", error_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta los clasificadores individuales del ejercicio anterior para hacer predicciones en el conjunto de entrenamiento y crea un nuevo conjunto de entrenamiento con las predicciones resultantes: cada instancia de entrenamiento es un vector que contiene el conjunto de predicciones de todos tus clasificadores para una imagen y el objetivo es la clase de la imagen. Entrena un clasificador (RandomForestClassifier) en este nuevo conjunto de entrenamiento. \n",
    "\n",
    "Acabas de entrenar un blender y, junto a los clasificadores, forma un ensamble de stacking.\n",
    "\n",
    "Ahora, evalúa el ensamble en el conjunto de prueba. \n",
    "\n",
    "¿Cómo es en comparación con el clasificador de votación que has entrenado antes?\n",
    "\n",
    "Haz lo mismo usando StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando predicciones con DecisionTreeClassifier\n",
      "Generando predicciones con RandomForestClassifier\n",
      "Generando predicciones con SVC\n",
      "Generando predicciones con KNeighborsClassifier\n",
      "Precisión del ensamble (blender): 0.9288\n",
      "Precisión del conjunto de prueba (VotingClassifier): 0.974\n",
      "Precisión del conjunto de prueba (StackingClassifier): 0.9806\n"
     ]
    }
   ],
   "source": [
    "# Cuidado con esto, tarda 35 minutos en ejecutar\n",
    "# Generar predicciones del conjunto de entrenamiento con cada clasificador\n",
    "predicciones_entrenamiento = []\n",
    "for estimator in estimadores:\n",
    "    print(f\"Generando predicciones con {estimator.__class__.__name__}\")\n",
    "    predicciones = estimator.predict(X_train)\n",
    "    predicciones_entrenamiento.append(predicciones)\n",
    "\n",
    "# Crear el nuevo conjunto de entrenamiento con las predicciones de los clasificadores\n",
    "X_train_blender = np.array(predicciones_entrenamiento).T  # ajustar la forma\n",
    "y_train_blender = y_train  # El target es el mismo\n",
    "\n",
    "# Entrenar el blender con RandomForestClassifier\n",
    "blender = RandomForestClassifier(random_state=42)\n",
    "blender.fit(X_train_blender, y_train_blender)\n",
    "\n",
    "# Evaluar el blender en el conjunto de prueba\n",
    "predicciones_prueba = []\n",
    "for estimator in estimadores:\n",
    "    predicciones = estimator.predict(X_test)\n",
    "    predicciones_prueba.append(predicciones)\n",
    "\n",
    "X_test_blender = np.array(predicciones_prueba).T  # ajustar la forma\n",
    "error_test_blender = blender.score(X_test_blender, y_test)\n",
    "print(\"Precisión del ensamble (blender):\", error_test_blender)\n",
    "\n",
    "# Comparación con VotingClassifier\n",
    "print(\"Precisión del conjunto de prueba (VotingClassifier):\", error_test)\n",
    "\n",
    "# Usar StackingClassifier para verificar el rendimiento\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=named_estimators,\n",
    "    final_estimator=RandomForestClassifier(random_state=42)\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "error_test_stacking = stacking_clf.score(X_test, y_test)\n",
    "print(\"Precisión del conjunto de prueba (StackingClassifier):\", error_test_stacking)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
