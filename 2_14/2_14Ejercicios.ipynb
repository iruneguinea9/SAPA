{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier,StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has entrenado cinco modelos diferentes en el mismo conjunto de entrenamiento exacto y todos consiguen una precisión del 95%, ¿hay alguna posibilidad de que puedas combinar estos modelos para obtener mejores resultados? \n",
    "\n",
    "Si la respuesta es sí, ¿cómo? Si la respuesta es no, ¿por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si, se pueden combinar. Hay varios metodos de combinación, el de votación, el de la media, el boosting y el bagging. Habría que elegir el adecuado. Al combinar modelos, podemos mejorar la precisión al basarse en los diferentes modelos en vez de en uno. Además, si los modelos estan entrenados con diferentes datos, esa diversidad puede ser clave para mejorar la precisión, ya que tendrá más valores de los que aprender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el conjunto de datos MNIST y divídelo en un conjunto de entrenamiento, un conjunto de validación y un conjunto de prueba (por ejemplo, utiliza 50.000 instancias para entrenamiento, 10.000 para validación y 10.000 para pruebas). \n",
    "\n",
    "Después, entrena varios clasificadores diferentes (uno de ellos que sea un árbol de decisión). \n",
    "\n",
    "A continuación, intenta combinarlos en un ensamble que supere en rendimiento a cada clasificador individual del conjunto de validación, utilizando hard voting. \n",
    "\n",
    "Una vez que hayas encontrado uno, pruébalo en el conjunto de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame=False, parser=\"auto\")\n",
    "X_mnist = mnist.data\n",
    "y_mnist =  mnist.target\n",
    "\n",
    "# 50.000 para entrenamiento\n",
    "X_train, y_train = X_mnist[:50_000], y_mnist[:50_000]\n",
    "# Las siguientes 10.000 para validación\n",
    "X_valid, y_valid = X_mnist[50_000:60_000], y_mnist[50_000:60_000]\n",
    "\n",
    "# Y las siguientes 10.000 para pruebas\n",
    "X_test, y_test = X_mnist[60_000:], y_mnist[60_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando  Regresión Lineal\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modelo \u001b[38;5;129;01min\u001b[39;00m modelos:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando \u001b[39m\u001b[38;5;124m\"\u001b[39m, modelo)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(X_train, y_train)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "modelos = {\n",
    "    \"Regresión Lineal\": LinearRegression(),\n",
    "    \"Regresión Logística\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "    \"Random forest\":DecisionTreeClassifier(random_state=42),\n",
    "    \"Ridge\":KNeighborsClassifier(),\n",
    "}\n",
    "\n",
    "for modelo in modelos:\n",
    "    print(\"Entrenando \", modelo)\n",
    "    modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta los clasificadores individuales del ejercicio anterior para hacer predicciones en el conjunto de entrenamiento y crea un nuevo conjunto de entrenamiento con las predicciones resultantes: cada instancia de entrenamiento es un vector que contiene el conjunto de predicciones de todos tus clasificadores para una imagen y el objetivo es la clase de la imagen. Entrena un clasificador (RandomForestClassifier) en este nuevo conjunto de entrenamiento. \n",
    "\n",
    "Acabas de entrenar un blender y, junto a los clasificadores, forma un ensamble de stacking.\n",
    "\n",
    "Ahora, evalúa el ensamble en el conjunto de prueba. \n",
    "\n",
    "¿Cómo es en comparación con el clasificador de votación que has entrenado antes?\n",
    "\n",
    "Haz lo mismo usando StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "nav_menu": {
   "height": "252px",
   "width": "333px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
